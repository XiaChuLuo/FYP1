{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLvFTNsuwu0V/4zxtKLtx7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XiaChuLuo/FYP1/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nkxfPNDHgHGw",
        "outputId": "6bc09c9e-2e72-4731-8df7-e27ce014ba43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 4, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 11, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/console.py\", line 62, in <module>\n",
            "    from .region import Region\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/region.py\", line 4, in <module>\n",
            "    class Region(NamedTuple):\n",
            "  File \"/usr/lib/python3.11/typing.py\", line 2927, in __new__\n",
            "    nm_tpl = _make_nmtuple(typename, types.items(),\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/typing.py\", line 2895, in _make_nmtuple\n",
            "    nm_tpl = collections.namedtuple(name, fields,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/collections/__init__.py\", line 503, in namedtuple\n",
            "    result = type(typename, (tuple,), class_namespace)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.9.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python matplotlib numpy pandas seaborn scikit-learn\n",
        "\n",
        "!pip install tensorflow keras\n",
        "\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iczsWXj0gPOv",
        "outputId": "3527ccad-eaad-4664-8c45-beb8563a1eac"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a Dataset Path\n",
        "\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/colored_images\"\n",
        "\n",
        "# Define class names based on folder names\n",
        "class_names = [\"Mild\", \"Moderate\", \"No_DR\", \"Proliferate_DR\", \"Severe\"]\n"
      ],
      "metadata": {
        "id": "FS0dAR-IllJD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Images For GAN training\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE = 128  # GAN prefers smaller images\n",
        "\n",
        "def load_images(path):\n",
        "    images = []\n",
        "    for file in glob.glob(os.path.join(path, \"*.png\")):  # Ensure it reads PNG files\n",
        "        img = cv2.imread(file, cv2.IMREAD_COLOR)  # Load image\n",
        "        if img is None:\n",
        "            print(f\"Warning: Unable to load {file}\")  # Debugging\n",
        "            continue\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # Resize\n",
        "        img = (img / 127.5) - 1  # Normalize to range [-1, 1]\n",
        "        images.append(img)\n",
        "\n",
        "    if len(images) == 0:\n",
        "        raise ValueError(f\"No images found in {path}!\")  # Avoid empty array issue\n",
        "\n",
        "    return np.array(images, dtype=np.float32)  # Ensure consistent type\n",
        "\n",
        "# Set BASE_DIR (Change to your dataset path)\n",
        "BASE_DIR = \"/content/drive/MyDrive/colored_images\"  # Modify this as needed\n",
        "\n",
        "# Define paths\n",
        "MILD_PATH = os.path.join(BASE_DIR, \"Mild\")\n",
        "SEVERE_PATH = os.path.join(BASE_DIR, \"Severe\")\n",
        "PDR_PATH = os.path.join(BASE_DIR, \"Proliferate_DR\")\n",
        "\n",
        "# Load images\n",
        "mild_images = load_images(MILD_PATH)\n",
        "severe_images = load_images(SEVERE_PATH)\n",
        "pdr_images = load_images(PDR_PATH)\n",
        "\n",
        "# Ensure all have the same dimensions\n",
        "print(f\"Mild: {mild_images.shape}, Severe: {severe_images.shape}, PDR: {pdr_images.shape}\")\n",
        "\n",
        "# Concatenate images\n",
        "train_images = np.concatenate([mild_images, severe_images, pdr_images], axis=0)\n",
        "print(f\"Training GAN on {train_images.shape[0]} images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNwSdfzlwHNy",
        "outputId": "d9a65a16-6ea6-4ad8-8079-e93721afd8a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mild: (370, 128, 128, 3), Severe: (193, 128, 128, 3), PDR: (295, 128, 128, 3)\n",
            "Training GAN on 858 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define GAN (Generator + Discriminator)\n",
        "\n",
        "#Generator\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(128 * 16 * 16, activation=\"relu\", input_shape=(100,)),\n",
        "        layers.Reshape((16, 16, 128)),\n",
        "        layers.Conv2DTranspose(128, (5,5), strides=(2,2), padding='same', activation='relu'),\n",
        "        layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', activation='relu'),\n",
        "        layers.Conv2DTranspose(3, (5,5), strides=(2,2), padding='same', activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxJBGRU-ycts",
        "outputId": "fd15031d-e32a-48d0-c78c-edf6877b4d84"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Discriminator\n",
        "\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (5,5), strides=(2,2), padding='same'),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBKQzVnryl_A",
        "outputId": "35c93ba1-5e8a-4333-8a78-1800913e7aad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train GAN\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Define hyperparameters\n",
        "EPOCHS = 3000\n",
        "BATCH_SIZE = 32\n",
        "NOISE_DIM = 100  # Latent space dimension for generator input\n",
        "\n",
        "# Define optimizers and loss function\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "# Loss functions for GAN training\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)  # Generator wants D(fake) → 1\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)  # D(real) → 1\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)  # D(fake) → 0\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "# Training function\n",
        "def train_step(real_images):\n",
        "    noise = tf.random.normal([real_images.shape[0], NOISE_DIM])  # Generate noise input\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        fake_images = generator(noise)  # Generate fake images\n",
        "        real_output = discriminator(real_images)\n",
        "        fake_output = discriminator(fake_images)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Compute gradients\n",
        "    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "\n",
        "\n",
        "    # Ensure gradients exist before applying\n",
        "    if None not in gen_gradients and None not in disc_gradients:\n",
        "        generator_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
        "    else:\n",
        "        print(\"⚠️ Gradients are None! Check model, loss function, or data!\")\n",
        "\n",
        "    return gen_loss, disc_loss  # Ensure two values are returned\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    idx = np.random.randint(0, train_images.shape[0], BATCH_SIZE)\n",
        "    real_batch = train_images[idx]\n",
        "    gen_loss, disc_loss = train_step(real_batch)\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Gen Loss: {gen_loss.numpy():.4f}, Disc Loss: {disc_loss.numpy():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zlmHztXpypD1",
        "outputId": "50d0ab60-01ac-4bcc-8e43-1a5be98c6ca2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Gen Loss: 3.8822, Disc Loss: 0.0642\n",
            "Epoch 500, Gen Loss: 5.5668, Disc Loss: 0.6806\n",
            "Epoch 1000, Gen Loss: 3.3167, Disc Loss: 0.2569\n",
            "Epoch 1500, Gen Loss: 1.0689, Disc Loss: 0.8113\n",
            "Epoch 2000, Gen Loss: 2.3377, Disc Loss: 0.2177\n",
            "Epoch 2500, Gen Loss: 1.1104, Disc Loss: 1.0036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saved the GAN model\n",
        "\n",
        "generator.save(\"/content/drive/MyDrive/FYP1_GAN_Model/generator.h5\")\n",
        "discriminator.save(\"/content/drive/MyDrive/FYP1_GAN_Model/discriminator.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hxn4pNe42q5",
        "outputId": "2bb68c01-1630-4cef-88a6-5b0b483aff2d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reload GAN models\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the trained models\n",
        "generator = load_model(\"/content/drive/MyDrive/FYP1_GAN_Model/generator.h5\")\n",
        "discriminator = load_model(\"/content/drive/MyDrive/FYP1_GAN_Model/discriminator.h5\")\n",
        "\n",
        "print(\"GAN Models Loaded Successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPB_lvae5IrC",
        "outputId": "ffdcbede-29e5-4d81-d678-383d38044e04"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "GAN Models Loaded Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate and Save Images\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "NOISE_DIM = 100  # Ensure NOISE_DIM is defined\n",
        "SAVE_PATH = \"/content/drive/MyDrive/colored_images/\"\n",
        "\n",
        "# Ensure folders exist for each DR class\n",
        "for folder in [\"Mild\", \"Severe\", \"Proliferate_DR\"]:\n",
        "    os.makedirs(os.path.join(SAVE_PATH, folder), exist_ok=True)\n",
        "\n",
        "# Generate and save 1000 new images\n",
        "for i in range(1000):\n",
        "    noise = tf.random.normal([1, NOISE_DIM])  # Generate random noise\n",
        "    fake_img = generator(noise, training=False).numpy()[0]  # Create fake image\n",
        "    fake_img = ((fake_img + 1) * 127.5).astype(np.uint8)  # Convert from [-1,1] to [0,255]\n",
        "\n",
        "    # ✅ Convert RGB to BGR to avoid blue tint\n",
        "    fake_img = cv2.cvtColor(fake_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # ✅ Assign images to respective class folders\n",
        "    if i % 3 == 0:\n",
        "        save_path = os.path.join(SAVE_PATH, \"Mild\", f\"fake_{i}.png\")\n",
        "    elif i % 3 == 1:\n",
        "        save_path = os.path.join(SAVE_PATH, \"Severe\", f\"fake_{i}.png\")\n",
        "    else:\n",
        "        save_path = os.path.join(SAVE_PATH, \"Proliferate_DR\", f\"fake_{i}.png\")\n",
        "\n",
        "    cv2.imwrite(save_path, fake_img)  # ✅ Save corrected image\n",
        "\n",
        "print(f\"✅ Generated images saved correctly in {SAVE_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwWJqYCX5P53",
        "outputId": "e40e6946-09d6-4956-9e1d-c6869b248690"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated images saved correctly in /content/drive/MyDrive/colored_images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load and Preprocess Images\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = 224  # MobileNetV2 standard input size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # 80-20 train-validation split\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    BASE_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    BASE_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTYNTxGqizft",
        "outputId": "977a8403-a921-4306-92ca-211c7eada7ea"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3740 images belonging to 6 classes.\n",
            "Found 932 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load MobileNetV2\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    include_top=False,  # Exclude final classification layer\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "base_model.trainable = False  # Freeze pre-trained layers\n"
      ],
      "metadata": {
        "id": "gMopF9m_jlU-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Model\n",
        "\n",
        "#Define Model\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(5, activation='softmax')  # 5 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "QJM0J19-jwaV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Model\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "5Jh6kSS6l1VM",
        "outputId": "b715c725-1d20-4389-e8ec-0c9ef0e5fa86"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 6), output.shape=(None, 5)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-326b102c29a3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    661\u001b[0m                 \u001b[0;34m\"Arguments `target` and `output` must have the same shape. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;34m\"Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 6), output.shape=(None, 5)"
          ]
        }
      ]
    }
  ]
}